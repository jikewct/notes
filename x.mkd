#upredis-proxy

# 主体设计

## 事件库：
- 处理顺序为ERR>READ>WRITE所以会出现：
1）redis断链之后，执行的是core_err->core_close->server_close；
2）如果有一个大的pipeline，proxy可能会一致读取，导致无法及时将请求发送到redis（大pipeline超时）
3) server突然断链那么导致正在等待回复的客户端收到server

- READ常驻/WRITE事件需要的时候添加

- libevent的rw事件可以分别设置为两个不同的event
  nc的事件机制中fd与cb(core_core)一一映射，core_core根据conn,events 按照E->R->W处理事件
  每个conn通过不同的recv,send,close函数指针定制不同的ERW行为。

- loop

a) 处理reload
b) event_wait   # 默认stats_interval 10ms; ctx->max_timeout也为10ms；
c) handle_accumulated_signal
d) core_timeout
e) core_before_sleep

## 消息

```
msg_recv
    while (conn->recv_ready)  # recv_ready==0的情况： EAGAIN; EOF; ERROR
        msg = conn->recv_next # 新msg或mbuf残余的nmsg
        msg_recv_chain  # 读满一个mbuf；对mbuf命令逐个msg解析；解析之后路由到对应的svr

msg_send
    while (conn->send_ready)
        msg = conn->send_next   # siq的迭代器
        msg_send_chain # 一次sendv；sendv之后对mbuf&msg逐个finalize

```

消息流转：

Client  READ: 读取msg; msg --> coq, msg --(forward)--> siq；添加sconn写事件
Server WRITE: siq --> msg; 发送msg；msg --> soq；
Server  READ: 读取pmsg; 与soq.first建立关联；msg从siq出队；添加cconn写事件
Client WRITE: coq --> msg；发送pmsg；soq -->；释放msg--pmsg

解析:

通过状态机实现: tokennize，state，流式, DFA

1)repair：如果token跨两个mbuf，那么将这个token切断到另一个mbuf；
2)again: token未被切断，但mbuf已经被扫描完成
3)ok: mbuf在被扫描完成之前，已经解析到一个完整的msg；如果一个msg跨越两个mbuf，那么该
    msg将悲切分为两个mbuf（i.e. msg与mbuf是一对多的关系）


路由和分片：
conn->recv_done # msg 读取解析完成的后续动作
1) 过滤： quit-在client所有reply收到后关闭连接，auth之前命令不forward，ping命令不forward，管理命令直接回复客户端不支持
2) forward：如果不需要forward，直接回复客户端；如果需要forward，则路由到指定的svr

## 异常处理

几个标记的说明

msg->done 标志着当前消息的回复已经读取到了
msg->err    msg无法给出正常回复的原因，通常是errno
msg->error  标志着该消息无法给出正常的回复（比如后端链路断了）
msg->ferror frament msg出错（ferror具有传染性）

conn->eof 当前连接收到了fin报文（关闭读取端口）
conn->done 当前连接可以关闭（所有回复都已经发送完毕）
conn->recv_active 添加了READ事件
conn->send_active 添加了WRITE事件
conn->err connection出现了err（比如send/recv失败)

CLIENT EOF:
由于无法区分客户端到底是close还是shutdown_rd，因此客户端断链当做shutdown_rd处理：
- 由于第二次向close的客户端send会引发EPIPE，因此proxy应该处理EPIPE错误
- 客户端close时，可能msg还没有完全写完，这部分消息将被丢弃
- 半关闭状态的客户端连接还能继续接受svr发来的rsp，因此proxy应该继续向client发送rsp

处理流程：
conn_recv给链路打上eof标记;conn->recv_next丢弃不完整msg；conn停止read；

SERVER EOF:
服务端EOF说明server已经不正常(crash或者错误了)，因此立即关闭链路。

处理流程：
conn_recv给链路打上eof标记;conn->recv_next丢弃不完整msg，标记链路done；conn停止read；
接着由于链路done，关闭server链接:
- 标记siq, soq中的msg为err
- 更新server->next_retry
- 标记server为dead 
- close

SERVER ERR:
过程同SERVER EOF

CLIENT ERR:
立即关闭客户端链接：
- 抛弃非完整req 
- 已经forward的req标记为swallow

协议错误：proxy,redis都直接关闭链接
命令不支持：redis回复-ERR unknown command 'xxx'; proxy将直接关闭链接
- 将conn标记为err
- 客户端/服务端链接被关闭

服务端重连：
- 服务端断链之前确定下次next_retry的时间
- before sleep时尝试重连重连

## 密码相关


## 超时处理

core_timeout 根据当前的rbtree计算event_wait等待的时间

如果req超时：
    - 标记conn为ETIMEOUT
    - 断开req所属的链接

为了处理connect超时，sever connect时会向tmo中添加一个fake msg:
- 如果connect正常：连接之后删除该fake msg
- 如果connect超时: fake msg超时，触发断链
以上操作避免了不可达的情况，connect超时需要很长时间


## 不同维度的命令描述

- filter
quit 

- frament

- swallow

- noforward
ping
auth
auth之前需要auth的命令
管理命令(reload_redis, reload_sentinel, stats, stats_all, migrate)

- noreply

## signals

日志等级up          sigttin
日志等级down        sigttou
重新打开日志文件    sighup
退出                sigint,sigterm(15)
开启reqlog          sigusr1
reload config       sigusr2
coredump            sigsegv


## 断链重连

server的初始化过程：

server_pool_init:
    conf_pool_each_transform:
        server_init:
            conf_server_each_transform: 根据conf初始化server struct
    server_pool_run: 初始化一致性哈希结构

server的链接建立过程：

core_ctx_create:
    server_pool_preconnect:
        server_pool_preconnect_fn:
            server_each_preconnect:
                server_connect:socket, setnonblock, setnodelay, event_add_out, connect

dead之后重连server
core_before_sleep: 
    server_reconnect_check:
        server_connect:socket, setnonblock, setnodelay, event_add_out, connect

autoeject之后重连
req_recv_done:过滤，路由接受到的req msg
    req_forward:
        server_pool_conn: 选择server,选择conn，链接conn
            server_connect:socket, setnonblock, setnodelay, event_add_out, connect

- server的建链过程发生在初始化preconnect，定时检查，req_forward时
- req_forward在server->dead时不connect，并且errno为ETIMEOUT
- reconnect只有在server->dead时进行重连
- dead表示fake eject：如果auto eject，直接eject;否则dead
- 恢复过程为：
server_pool_conn:
    server_pool_update: 根据server_retry_timeout设置的next_rebuild，更新continuum

对于非auto_eject而言，每次断链都会造成server_dead；


综上：
- preconnect，初始化链接(dead=0)
- 断链之后，每个server_retry_timeout之后重连（被动|auto_eject_hosts, 主动|!auto_eject_host)


对于slave创建链接的启发：
- 设置slave的dead=0, 初始化链接，而且preconnect **WITH TIMEOUT**
- 断链之后，每隔server_retry_timeout之后重连

在preconnect成功之前，proxy收到了req怎么办？:
req_recv_done:
    req_forward:
        server_pool_conn: 返回一个connecting或者connected的链接
            server_pool_server
            server_conn
            server_connect
        enqueue siq:

综上： connecting的链接等同于链接好的链接

对于slave链接的启发：
- 发现新的slave之后preconnect
- slave dead 断链之后，每隔server_retry_timeout重连



隔离操作：

trick：server_close实际上的意思是conn_close;

server_each_preconnect:connect失败，关闭连接
    server_close: 如果conn->sd==-1,直接销毁conn;否则，销毁消息队列，然后再销毁conn
        server_failure: 
            server->dead = 1; 或者 server->failure_count++

server_reconnect_check:connect失败，close连接
    server_close

server_pool_conn: connect失败，close连接
    server_close

connection_is_drained:??
    server_close

core_ctx_destroy:
    server_pool_disconnect
        server_pool_disconnect_fn:
            server_each_disconnect:
                conn->close:
...



恢复操作：
a) auto_eject_hosts:
到了next_rebuild之后，对当前需要rebuild的servers，update continuum；
这样的话server被重新添加到可用svrs中

b) !auto_eject_hosts:
到了server->next_retry之后，发起reconnect操作，reconnect成功之后dead=0

关于dead的考究:
server_close:
    server_failure: 
        server->dead = 1; 或者 server->failure_count++
所以对于connection大于1的server，只要一个连接出现错误，则判断server dead是不合理的！

## 密码管理

大体思路： 加密密码>明文密码>dbpm

proxy密码配置：
redis_auth: foobared
redis_auth_s: 1b58ee375b42e41f0e48ef2ff27d10a5b1f6924a9acdcdba7cae868e7adce6bf
dbpms:
    - IP1:PORT1:db1:usr1
    - IP2:PORT2:db2:usr2

实现思路：

conn->need_auth  配置了redis_auth后，链路被标记为need_auth
conn->authing    发送了auth命令之后，链路被标记为authing
conn->dup_auth   pipe_q非空，然后又来了一个auth报文，则链路被标记为dup_auth；
                然后redis_reply时回复DUP_AUTH之后，又将dup_auth标记撤除
AUTH处理流程:
req_recv_done:
    if (msg->noforward):
        req_make_reply:创建reply结构
        msg->reply:(redis_reply)
            如果dup_auth则回复DUP_AUTH
            如果need_auth则回复NEED_AUTH
            如果是auth命令则将auth命令传递到对应的conn:redis_handle_auth_req

        if msg is ping:
            reply pong

redis_handle_auth_req:
    dbpm_select:
        dbpm_connect:
        发送dbpm请求

按照密文>明文>dbpm的级别对比密码


dbpm密码支持：
- conn->usr_auth表示sha256编码的密码，用于与返回的dbpm密码对比
- noforward的命令包括：auth之前的所有命令；ping; auth; auth_s;
- noforward的命令都会直接由conn->reply(redis_reply)处理
- authing过程中的命令全部放在conn->pipe_q中


## 监控管理

之前已经分析过，收到客户端stats命令之后，mgm转发、聚合stats信息，然后再返回客户端
json报文。


分析stats线程与worker线程之间的数据交换，分析为何出现coredump:
stats监控的数据：

```
pool stats:
client_eof          "# eof on client connections"
client_err          "# errors on client connections"
client_connections  "# active client connections"
server_ejects       "# times backend server was ejected"
forward_error       "# times we encountered a forwarding error"
fragments           "# fragments created from a multi-vector request"

server stats:
server_eof          "# eof on server connections"
server_err          "# errors on server connections"
server_timedout     "# timeouts on server connections"
server_connections  "# active server connections"
server_ejected_at   "timestamp when server was ejected in usec since epoch"
requests            "# requests"
request_bytes       "total request bytes"
responses           "# responses"
response_bytes      "total response bytes"
in_queue            "# requests in incoming queue"
in_queue_bytes      "current request bytes in incoming queue"
out_queue           "# requests in outgoing queue"
out_queue_bytes     "current request bytes in outgoing queue"

```

看样子upredis-proxy只是修改了proxy的stats信息获取方式，没有修改stats监控的数据种类：

stats_server_set_ts
    _stats_server_set_ts
        stats_server_to_metric:

        stm->value.timestamp = val


总体设计：

stats有shadow, current, sum三个stats_pool[]: sum = shadow + current，其中shadow, sum从属于stats aggregator线程
current从属于worker线程，当current move到 shadow时需要使用shadow_lock锁.

struct stats：
- shadow，current，sum
- 各种string
- 链路相关ns_conn_q, s_conn_q， next_retry等
- stats信息数组[] client_eof, server_eof, fragments等

struct stats_pool:
    name
    metric: stats_metic[]
    server: stats_server[]

struct stats_server:
    name
    metric: stats_metric[]

struct stats_metric:
    type
    name
    value

typedef enum stats_type:
    STATS_INVALID,
    STATS_COUNTER,    /* monotonic accumulator */
    STATS_GAUGE,      /* non-monotonic accumulator */
    STATS_TIMESTAMP,  /* monotonic timestamp (in nsec) */
    STATS_SENTINEL


stats aggregate:

stats_rsp_recv_done:
    stats_aggregate:
        locK shadow_lock
        foreach pool:
            stats_aggregate_metric
            foreach server:
                stats_aggregate_metric
        unlock shadow_lock

stats swap:在server处于稳定状态时，每个evloop都进行统计数据交换;server在reloading时不
交换stats信息

stats_swap:
    array_swap(current, shadow)
    stats_pool_reset(current)


stats的初始化和清理：

{core_worker_create, core_mgm_start, core_worker_recreate}
    stats_create:
        stats_pools_create
            stats_pool_map: 分别初始化current, shadown, sum
                stats_pool_each_init
                    stats_pool_init: # 初始化 pool metric
                        stats_pool_metric_init
                            stats_metric_init
                        stats_server_map # 初始化svrs metric
                            stats_server_init
                                stats_server_metric_init: #初始化或者继承统计值
                                    if (GAUGE && !recount)
                                        继承server初始化之前的数值！
                                    else 
                                        stats_metric_init

reload删除server，stats怎么删除对应的server：

## 动态生效

ctx->reload_sig 发起reload的标记（kill -SIGUSR2; reload_redis; +switch-master)

ctx->reload_delay: worker try reload again? 标记为reload2，排在当前reload之后的reload请求

ctx->failover_reloading: 

ctx->state:
    CTX_STATE_STEADY,
    CTX_STATE_RELOADING,
    CTX_STATE_RELOADED,

ctx->stats_reload_redis
    STATS_RELOAD_INIT = 0,
    STATS_RELOAD_START, 
    STATS_RELOAD_WAITING, 
    STATS_RELOAD_OK, 
    STATS_RELOAD_FAIL, 

ctx->req_stats
    STATS_REQ_INIT,
    STATS_RELOAD_REDIS,
    STATS_MIGRATE_START,
    STATS_MIGRATE_DOING,
    STATS_RELOAD_REDIS_MIGRATING,
    STATS_MIGRATE_END,
    STATS_STATS,
    STATS_STATS_ALL,


core_loop
    core_before_sleep
        core_reload_check
            if (ctx->stats_reload_redis == STATS_RELOAD_START
                if ctx->state != CTX_STATE_RELOADING:
                    config_reload_redis
                        server_pool_init replacement_pools
                        server_pools_kick_replacement
                        ctx->state = CTX_STATE_RELOADING;
                    ctx->stats_reload_redis = STATS_RELOAD_WAITING;
                else # reloading时，又来了reload命令，即reload2
                    ctx->reload_delay = 1

core_loop
    core_timeout
        core_timeout_reply: 对于超时mgm消息，回应-err timeout
            if (st->alive_cnt == st->cmd_suc_cnt + st->cmd_fail_cnt + st->cmd_timeo_cnt
                && ctx->reload_delay) # 超时，reload2上位为reload
                ctx->reload_delay = 0
                ctx->reload_sig = 1

core_loop:
    if (ctx->state is CTX_STATE_STEADY or CTX_STATE_RELOADED)
        stats_swap
    if (ctx->state is CTX_STATE_RELOADING)
        if server_pools_finish_replacement
            ctx->state = CTX_STATE_RELOADED
        else
            timeout = 10ms

stats_loop
    if worker:
        stats_before_event_wait
            stats_check_reload_redis_finish: 如果WAITING、INIT、START，则返回；如果OK, FAIL则回复相应结果
            
    if master && ctx->reload_sig
        stats_failover_reload:
           if (ctx->req_stats != STATS_REQ_INIT)
               ctx->reload_delay = 1
           else 
               ctx->failover_reloading = 1
               stats_req_forward

stats_rsp_recv_done
    stats_rsp_forward
        stats_make_rsp

stats_req_recv_done
    stats_req_forward
    stats_req_check
        if (msg->type == MSG_REQ_REDIS_RELOAD_REDIS)
            ctx->reload_delay = 1; #如果mgm正在执行其他管理命令，来了reload请求之后，reload排队(reload2)

stats_server_close:
    if (ctx->reload_delay)
        ctx->stats_reload_redis = STATS_RELOAD_START;

### mgm进程：

>>> mgm线程
mgm线程在几乎不对reload有任何影响，只用于响应shutdown命令

>>> stats线程
如果发现当前ctx->reload_sig，则将reload信号分发到各worker；
（分发了reload信号之后，收集reload响应的工作在rsp_recv_done中处理）

>>> monitor线程
侦听+switch-master消息，修改配置文件，将ctx->reload_sig置为1

### worker进程：

>>> stats线程
收到了reload req，则启动reload(ctx->stats_reload_redis = STATS_RELOAD_START)
worker与mgm之间的链路断掉时发现有reload2，则启动reload

定期检查reload是否完成(ctx->stats_reload_redis为OK, FAIL), 并且将结果回复给mgm进程(WAITING)

>>> worker线程
检查reload是否启动(ctx->stats_reload_redis处于STATS_RELOAD_START)如果启动,则执行reload(config_reload_redis)
每个loop都检查reload过程是否完成；如果完成则ctx->stats_reload_redis = STATS_RELOAD_OK


### reload过程中stats_pool和server_pool的联动分析：
- reload过程中不会执行stats_swap，也就是说stats信息被冻结了！
- reload过程中的


## 读写分离


对于读写分离来讲：
开启：确认能够初始化相应结构，并且添加相应stats结构；将负载分配到slave中
关闭：确认能够正常地清理slave，并且读取请求不在分配到slave；判断reload结束需要考虑到slave


总体设计思路：

1. server添加stats_server[]，用于统计slave指标
2. 考虑slaves队列换成slave列表，这样的话slaves[]可以和stats_slave[]对应，在slave由于
info replication结果变更的时候，reset stats_slavs[]
